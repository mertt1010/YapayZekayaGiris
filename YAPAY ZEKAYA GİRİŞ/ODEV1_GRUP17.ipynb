{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137efc77-245b-481f-be1d-7a5e67a191c0",
   "metadata": {},
   "source": [
    "# YAPAY ZEKAYA GİRİŞ\n",
    "### ODEV 1\n",
    "Ödevde istenilen değerler sırası ile bunlardır\n",
    "\n",
    "- İbrahim Serhat Aktaş = 210601020\n",
    "\n",
    "- Mert Tosun           = 210601027\n",
    "\n",
    "- Kutay Can Batur      = 210601009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "408ecb29-7480-477e-b6de-5abe31c6323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sistem belirtilen yolu bulam�yor.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 1314] Gereken ayrıcalık istemci tarafından sağlanmıyor: '/kaggle/input' -> '..\\\\input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(KAGGLE_WORKING_PATH, \u001b[38;5;241m0o777\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m   \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKAGGLE_INPUT_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m..\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_is_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1314] Gereken ayrıcalık istemci tarafından sağlanmıyor: '/kaggle/input' -> '..\\\\input'"
     ]
    }
   ],
   "source": [
    "\n",
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
    "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import unquote, urlparse\n",
    "from urllib.error import HTTPError\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "CHUNK_SIZE = 40960\n",
    "DATA_SOURCE_MAPPING = 'breast-histopathology-images:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F7415%2F10564%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240609%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240609T192018Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D543ca114d5882b35e003f0d8b6f275a2e14b3a6b7c4abd003b6f478a3cede46cf7a6a44c2ce088e280fbbc688cc1ae2c90975e8d278f6d5ba127493aa354bb029a01561a3f6896ddd0bb81a75dc568c9731b634b0c2f2fcda6e7f06e3de045a539f16ab4145d7fca5e0686afb6e607494c5eed8000f835c66f7b703e1b95443d674c61e864b49ee6aa500fd7a7081787569aedfa9b244a0ce9314173bbc19b923caa5b9add73fef3a88912c2e5c8a78f4371af4d1af7803d1fa3db187557230d3aa222de3e37bdfd8d599d548de20bbf007e1959e25a8d8f8e30933f29217daff14df691b3ce73902b79187e0daa470cdef5a03ec72afe73138ccd86337d2570,cbis-ddsm-breast-cancer-image-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1115384%2F1873742%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240609%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240609T192018Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D779f333a2b1c00484c594ae7390320383a450568ff9bb76dc18af800f34501873d7cbc4a742e25b7fc2b398292654fbfac9ae7efd48a4830db9b287a4efcb13692b44d2613860cca0e649d3c06e4d13f55bd8d51c006d215d6cad88ba9662f1518a9e8ce7dca4d9c45bc11053b43b1b18dc9ba63aa5dfd79227f5a98bee73aa25b376921837d12c1c77d73e3d6fe8b8a29c847e3f7927f505bb7c579407a9c97194fa47722817c2931fb7d77ba13676d6283b6a0e1fd3d3b5aed4d88bbd23c69513842447845ef803c0e662b8126aedc779ba763acf3234c68c6e4d951ce1627cb6a5d6e2d451fb1b04ae9d4508e8960fc8885e451a3c925a2e259f6e5fb78e1'\n",
    "\n",
    "KAGGLE_INPUT_PATH='/kaggle/input'\n",
    "KAGGLE_WORKING_PATH='/kaggle/working'\n",
    "KAGGLE_SYMLINK='kaggle'\n",
    "\n",
    "!umount /kaggle/input/ 2> /dev/null\n",
    "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
    "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
    "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
    "\n",
    "try:\n",
    "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "try:\n",
    "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "\n",
    "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
    "    directory, download_url_encoded = data_source_mapping.split(':')\n",
    "    download_url = unquote(download_url_encoded)\n",
    "    filename = urlparse(download_url).path\n",
    "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
    "    try:\n",
    "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
    "            total_length = fileres.headers['content-length']\n",
    "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
    "            dl = 0\n",
    "            data = fileres.read(CHUNK_SIZE)\n",
    "            while len(data) > 0:\n",
    "                dl += len(data)\n",
    "                tfile.write(data)\n",
    "                done = int(50 * dl / int(total_length))\n",
    "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
    "                sys.stdout.flush()\n",
    "                data = fileres.read(CHUNK_SIZE)\n",
    "            if filename.endswith('.zip'):\n",
    "              with ZipFile(tfile) as zfile:\n",
    "                zfile.extractall(destination_path)\n",
    "            else:\n",
    "              with tarfile.open(tfile.name) as tarfile:\n",
    "                tarfile.extractall(destination_path)\n",
    "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
    "    except HTTPError as e:\n",
    "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
    "        continue\n",
    "    except OSError as e:\n",
    "        print(f'Failed to load {download_url} to path {destination_path}')\n",
    "        continue\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fa6abd-083c-4e90-90c8-e0ac7753347d",
   "metadata": {},
   "source": [
    "Değerler sırası ile aşağıdaki gibidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306654a1-f37a-43d5-a5f6-ac5427adb357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd                              # for data manipulation and analysis\n",
    "import numpy as np                               # for numerical operations\n",
    "import cv2                                       # openCv for computer vision tasks\n",
    "from PIL import Image                            # python imaging library for image processing \n",
    "import matplotlib.pyplot as plt                  # for creating plots and visualisations\n",
    "import plotly.express as px                      # interactive plotting library\n",
    "import seaborn as sns                            # statistical data visualization\n",
    "import glob                                      # for searching files using patterns\n",
    "import random                                    # for generating random numbers\n",
    "import os                                        # for interacting with operating system\n",
    "import pydicom                                   # for working with DICOM files\n",
    "from keras.utils import load_img, img_to_array   # keras utils for loading and converting images\n",
    "import tensorflow as tf                          # for deep learning\n",
    "from os import listdir                           # for listing files in directory\n",
    "from matplotlib.image import imread              # for reading images\n",
    "from sklearn.metrics import classification_report, confusion_matrix  # for model evaluation\n",
    "from keras.utils import to_categorical           # for converting to categorical data\n",
    "from sklearn.model_selection import train_test_split  # for splitting dataset\n",
    "from tensorflow.keras.models import load_model   # for loading models\n",
    "from tensorflow.keras import layers              # for creating neural network layers\n",
    "from keras_cv import models as keras_cv_models   # for keras CV models\n",
    "import time                                      # for timing operations\n",
    "from concurrent.futures import ThreadPoolExecutor  # for parallel processing\n",
    "import matplotlib.image as mpimg                 # for displaying images\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(100)\n",
    "np.random.seed(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d04bb",
   "metadata": {},
   "source": [
    "Gerekli kütüphaneleri ekleyelim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccd58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_data = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/dicom_info.csv')\n",
    "#image_dir = '/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/jpeg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130dba3b-1c19-41bb-8e76-88614e9d24ec",
   "metadata": {},
   "source": [
    "Bizden istenilen fonksyon \"y = acos(bx + c) + d\". \n",
    "\n",
    "Şimdi 20 adet örnek rastgele sonuç çıkaralım.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468539b2-48c0-4040-8ff4-a6236bc0108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter 'dicom_data' DataFrame to select rows where 'SeriesDescription' is 'cropped images'\n",
    "cropped_images=dicom_data[dicom_data.SeriesDescription == 'cropped images'].image_path\n",
    "\n",
    "# Set the directory path for JPEG images\n",
    "image_dir = '../input/cbis-ddsm-breast-cancer-image-dataset/jpeg'\n",
    "\n",
    "cropped_images = cropped_images.apply(lambda x: x.replace('CBIS-DDSM/jpeg', image_dir))\n",
    "for file  in cropped_images[0:5]:\n",
    "  cropped_images_show = PIL.Image.open(file)\n",
    "# Convert the image to grayscale\n",
    "  gray_img= cropped_images_show.convert(\"L\")\n",
    "  plt.imshow(gray_img, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5af334",
   "metadata": {},
   "source": [
    "Şimdi tek bir giriş ve tek bir çıkış birimine sahip basit bir sinir ağı modeli oluşturalım. \n",
    "Bu kod parçası, TensorFlow kullanarak, tek bir girişe sahip (input_shape=[1]) ve dört birime (units=4) sahip yoğun (Dense) bir katman içeren bir yapay sinir ağı modeli oluşturur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29357c77-0b44-4c78-b071-bdc818856018",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_mammogram_images=dicom_data[dicom_data.SeriesDescription == 'full mammogram images'].image_path\n",
    "full_mammogram_images = full_mammogram_images.apply(lambda x: x.replace('CBIS-DDSM/jpeg', image_dir))\n",
    "for file  in full_mammogram_images[0:5]:\n",
    "  full_mammogram_images_show = PIL.Image.open(file)\n",
    "  gray_img= full_mammogram_images_show.convert(\"L\")\n",
    "  plt.imshow(gray_img, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f45a4",
   "metadata": {},
   "source": [
    "Modelin derlenmesi işlemi, kayıp fonksiyonu olarak mean_squared_error ve optimizasyon algoritması olarak Adam optimizer kullanılarak yapılır. Adam optimizer'ın öğrenme oranı (learning rate) 0.1 olarak belirlenmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fcd3cd-c2a6-4c0a-a7ac-acebcd482523",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_mask_images=dicom_data[dicom_data.SeriesDescription == 'ROI mask images'].image_path\n",
    "ROI_mask_images = ROI_mask_images.apply(lambda x: x.replace('CBIS-DDSM/jpeg', image_dir))\n",
    "for file  in ROI_mask_images[0:5]:\n",
    "    # Open the image using PIL (Python Imaging Library)\n",
    "  ROI_mask_images_show = PIL.Image.open(file)\n",
    "  gray_img= ROI_mask_images_show.convert(\"L\")\n",
    "  plt.imshow(gray_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b623cb66",
   "metadata": {},
   "source": [
    "Model, oluşturulan giriş ve çıktı dizileri kullanılarak eğitilir. Eğitim süreci 500 dönem (epoch) sürer ve eğitim sırasındaki ilerleme bilgisi gösterilmez (verbose=False). Eğitim tamamlandığında bir mesaj yazdırılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b8d753-6c13-4e72-a16c-25d3777c2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_case_df = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/calc_case_description_train_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8b8002",
   "metadata": {},
   "source": [
    "Bu kod parçası, eğitim süreci boyunca kayıp değerlerinin nasıl değiştiğini gösteren bir grafik çizer. Bu, modelin eğitim sürecindeki performansını gözlemlemek için kullanılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876906af-cf6a-43fd-8611-e34b44e6be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_case_df = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/mass_case_description_train_set.csv')\n",
    "# Read CSV files into DataFrames\n",
    "mass_case_test_df=pd.read_csv('../input/cbis-ddsm-breast-cancer-image-dataset/csv/mass_case_description_test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847e235a-e4c6-4017-b98a-dcabdeb2f8b0",
   "metadata": {},
   "source": [
    "10 Adet test sonucu:\n",
    "\n",
    "Model, 10 adet yeni rastgele x değeri üzerinde test edilir. Her bir test için, modelin tahmini (model.predict(test)) ve gerçek değer (a * np.cos(b*sayi + c) + d) yazdırılır. Bu, modelin genelleme kabiliyetini ve tahmin doğruluğunu değerlendirmek için kullanılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b118af-aba6-4711-995c-28e054aca23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_cleaned_data = dicom_data.copy()\n",
    "dicom_cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbefc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_cleaned_data.drop(['PatientBirthDate','AccessionNumber','Columns','ContentDate','ContentTime',\n",
    "                         'PatientSex','PatientBirthDate','ReferringPhysicianName','Rows','SOPClassUID','SOPInstanceUID',\n",
    "                         'StudyDate','StudyID','StudyInstanceUID','StudyTime','InstanceNumber','SeriesInstanceUID','SeriesNumber'\n",
    "                        ],axis =1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d48371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sütunda bulunan eksik değerleri bir sonraki değer ile dolduralım\n",
    "dicom_cleaned_data['SeriesDescription'].ffill(inplace=True)\n",
    "dicom_cleaned_data['Laterality'].bfill(inplace=True)\n",
    "dicom_cleaned_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9a61ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_cleaning_1 = calc_case_df.copy()\n",
    "# Aşağıdaki satırlarda isim değişikliği yapılmıştır.\n",
    "Data_cleaning_1 = Data_cleaning_1.rename(columns={'calc type':'calc_type'})\n",
    "Data_cleaning_1 = Data_cleaning_1.rename(columns={'calc distribution':'calc_distribution'})\n",
    "Data_cleaning_1 = Data_cleaning_1.rename(columns={'image view':'image_view'}) \n",
    "Data_cleaning_1 = Data_cleaning_1.rename(columns={'left or right breast':'left_or_right_breast'})\n",
    "Data_cleaning_1 = Data_cleaning_1.rename(columns={'breast density':'breast_density'})\n",
    "Data_cleaning_1 = Data_cleaning_1.rename(columns={'abnormality type':'abnormality_type'})\n",
    "\n",
    "# Belirtilen sütunlardaki veri tiplerini kategorik tipe dönüştürür.\n",
    "Data_cleaning_1['pathology'] = Data_cleaning_1['pathology'].astype('category')\n",
    "Data_cleaning_1['calc_type'] = Data_cleaning_1['calc_type'].astype('category')\n",
    "Data_cleaning_1['calc_distribution'] = Data_cleaning_1['calc_distribution'].astype('category')\n",
    "Data_cleaning_1['abnormality_type'] = Data_cleaning_1['abnormality_type'].astype('category')\n",
    "Data_cleaning_1['image_view'] = Data_cleaning_1['image_view'].astype('category')\n",
    "Data_cleaning_1['left_or_right_breast'] = Data_cleaning_1['left_or_right_breast'].astype('category')\n",
    "\n",
    "Data_cleaning_1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Belirtilen sütunlar için tekrardan veri doldurma işlemi yapılır.\n",
    "Data_cleaning_1['calc_type'].bfill(inplace=True)\n",
    "Data_cleaning_1['calc_distribution'].bfill(inplace=True)\n",
    "Data_cleaning_1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86aea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of 'data_2_test' DataFrame for cleaning\n",
    "Data_cleaning_2_test = mass_case_test_df.copy()\n",
    "\n",
    "# Rename columns in 'Data_cleaning_2_test' DataFrame\n",
    "Data_cleaning_2_test = Data_cleaning_2_test.rename(columns={'mass shape':'mass_shape'})\n",
    "Data_cleaning_2_test = Data_cleaning_2_test.rename(columns={'left or right breast':'left_or_right_breast'})\n",
    "Data_cleaning_2_test = Data_cleaning_2_test.rename(columns={'mass margins':'mass_margins'})\n",
    "Data_cleaning_2_test = Data_cleaning_2_test.rename(columns={'image view':'image_view'})\n",
    "Data_cleaning_2_test = Data_cleaning_2_test.rename(columns={'abnormality type':'abnormality_type'})\n",
    "# Convert specified columns in 'Data_cleaning_2_test' to the 'category' data type\n",
    "Data_cleaning_2_test['left_or_right_breast'] = Data_cleaning_2_test['left_or_right_breast'].astype('category')\n",
    "Data_cleaning_2_test['image_view'] = Data_cleaning_2_test['image_view'].astype('category')\n",
    "Data_cleaning_2_test['mass_margins'] = Data_cleaning_2_test['mass_margins'].astype('category')\n",
    "Data_cleaning_2_test['mass_shape'] = Data_cleaning_2_test['mass_shape'].astype('category')\n",
    "Data_cleaning_2_test['abnormality_type'] = Data_cleaning_2_test['abnormality_type'].astype('category')\n",
    "Data_cleaning_2_test['pathology'] = Data_cleaning_2_test['pathology'].astype('category')\n",
    "# Display the count of missing values in each column of 'Data_cleaning_2_test' DataFrame\n",
    "Data_cleaning_2_test.isna().sum()\n",
    "# Fill missing values in 'mass_margins' column of 'Data_cleaning_2_test' DataFrame using backward fill\n",
    "Data_cleaning_2_test['mass_margins'].fillna(method = 'bfill', axis = 0, inplace=True) \n",
    "# Display the count of missing values in each column of 'Data_cleaning_2' DataFrame\n",
    "Data_cleaning_2_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d044e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_cleaning_2 = mass_case_df.copy()\n",
    "# isim değiştirme\n",
    "Data_cleaning_2 = Data_cleaning_2.rename(columns={'mass shape':'mass_shape'})\n",
    "Data_cleaning_2 = Data_cleaning_2.rename(columns={'left or right breast':'left_or_right_breast'})\n",
    "Data_cleaning_2 = Data_cleaning_2.rename(columns={'mass margins':'mass_margins'})\n",
    "Data_cleaning_2 = Data_cleaning_2.rename(columns={'image view':'image_view'})\n",
    "Data_cleaning_2 = Data_cleaning_2.rename(columns={'abnormality type':'abnormality_type'})\n",
    "#Veri tipini değiştirme\n",
    "Data_cleaning_2['left_or_right_breast'] = Data_cleaning_2['left_or_right_breast'].astype('category')\n",
    "Data_cleaning_2['image_view'] = Data_cleaning_2['image_view'].astype('category')\n",
    "Data_cleaning_2['mass_margins'] = Data_cleaning_2['mass_margins'].astype('category')\n",
    "Data_cleaning_2['mass_shape'] = Data_cleaning_2['mass_shape'].astype('category')\n",
    "Data_cleaning_2['abnormality_type'] = Data_cleaning_2['abnormality_type'].astype('category')\n",
    "Data_cleaning_2['pathology'] = Data_cleaning_2['pathology'].astype('category')\n",
    "Data_cleaning_2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a56d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boş verileri dolduralım\n",
    "Data_cleaning_2['mass_shape'].bfill(inplace=True) \n",
    "Data_cleaning_2['mass_margins'].bfill(inplace=True)  \n",
    "Data_cleaning_2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb74c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with counts of unique values in 'SeriesDescription' column\n",
    "r= pd.DataFrame(dicom_cleaned_data['SeriesDescription'].value_counts())\n",
    "# Reset the index to have 'SeriesDescription' as a column\n",
    "r= r.reset_index()\n",
    "# Rename columns for clarity\n",
    "r= r.rename(columns={'SeriesDescription':'SeriesDescription_counts', 'index':'SeriesDescription'})\n",
    "# Display the DataFrame\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the original column names in Data_cleaning_2 DataFrame\n",
    "print(Data_cleaning_2.columns)\n",
    "print('\\n')\n",
    "# Rename selected columns in Data_cleaning_2 DataFrame for better clarity\n",
    "Data_cleaning_2 = Data_cleaning_2.rename(columns={'left or right breast': 'left_or_right_breast',\n",
    "                                           'image view': 'image_view',\n",
    "                                           'abnormality id': 'abnormality_id',\n",
    "                                           'abnormality type': 'abnormality_type',\n",
    "                                           'mass shape': 'mass_shape',\n",
    "                                           'mass margins': 'mass_margins',\n",
    "                                           'image file path': 'image_file_path',\n",
    "                                           'cropped image file path': 'cropped_image_file_path',\n",
    "                                           'ROI mask file path': 'ROI_mask_file_path'})\n",
    "\n",
    "# Display the updated column names in Data_cleaning_2 DataFrame\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84913830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the original column names in Data_cleaning_2_test DataFrame\n",
    "print(Data_cleaning_2_test.columns)\n",
    "print('\\n')\n",
    "# Rename selected columns in Data_cleaning_2_test DataFrame for better clarity\n",
    "Data_cleaning_2_test = Data_cleaning_2_test.rename(columns={'left or right breast': 'left_or_right_breast',\n",
    "                                           'image view': 'image_view',\n",
    "                                           'abnormality id': 'abnormality_id',\n",
    "                                           'abnormality type': 'abnormality_type',\n",
    "                                           'mass shape': 'mass_shape',\n",
    "                                           'mass margins': 'mass_margins',\n",
    "                                           'image file path': 'image_file_path',\n",
    "                                           'cropped image file path': 'cropped_image_file_path',\n",
    "                                           'ROI mask file path': 'ROI_mask_file_path'})\n",
    "\n",
    "# Display the updated column names in Data_cleaning_2_test DataFrame\n",
    "Data_cleaning_2_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c60dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize image paths\n",
    "full_mammo_dict = dict()\n",
    "cropped_images_dict = dict()\n",
    "roi_img_dict = dict()\n",
    "# Iterate through full_mammogram_images and create a dictionary with keys based on unique identifiers\n",
    "for dicom in full_mammogram_images:\n",
    "    key = dicom.split(\"/\")[4]\n",
    "    full_mammo_dict[key] = dicom\n",
    "# Iterate through cropped_images and create a dictionary with keys based on unique identifiers\n",
    "for dicom in cropped_images:\n",
    "    key = dicom.split(\"/\")[4]\n",
    "    cropped_images_dict[key] = dicom\n",
    "# Iterate through ROI_mask_images and create a dictionary with keys based on unique identifiers\n",
    "\n",
    "for dicom in ROI_mask_images:\n",
    "    key = dicom.split(\"/\")[4]\n",
    "    roi_img_dict[key] = dicom\n",
    "\n",
    "# Display the keys of the first item in full_mammo_dict\n",
    "next(iter((full_mammo_dict.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769ea303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix image paths\n",
    "def fix_image_path(data):\n",
    "    \"\"\"correct dicom paths to correct image paths\"\"\"\n",
    "    for index, img in enumerate(data.values):\n",
    "        img_name = img[11].split(\"/\")[2]\n",
    "        data.iloc[index,11] = full_mammo_dict[img_name]\n",
    "        img_name = img[12].split(\"/\")[2]\n",
    "        data.iloc[index,12] = cropped_images_dict[img_name]\n",
    "        \n",
    "# apply to datasets\n",
    "fix_image_path(Data_cleaning_2)\n",
    "fix_image_path(Data_cleaning_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa130ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to display images\n",
    "def display_images(column, number):\n",
    "    \"\"\"displays images in the dataset\"\"\"\n",
    "    # create figure and axes\n",
    "    number_to_visualize = number\n",
    "    rows = 1\n",
    "    cols = number_to_visualize\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5))\n",
    "    \n",
    "    # Loop through rows and display images\n",
    "    for index, row in Data_cleaning_2.head(number_to_visualize).iterrows():\n",
    "        image_path = row[column]\n",
    "        image = mpimg.imread(image_path)\n",
    "        col_index = index % cols  # Calculate the correct column index\n",
    "        ax = axes[col_index]\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.set_title(f\"{row['pathology']}\")\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print('Full Mammograms:\\n')\n",
    "display_images('image_file_path', 5)\n",
    "print('Cropped Mammograms:\\n')\n",
    "display_images('cropped_image_file_path', 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66afdf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_image_path2(data):\n",
    "    \"\"\"Fixes image paths in the dataframe\"\"\"\n",
    "    for index, img in enumerate(data.values):\n",
    "        # Extract image name from the path\n",
    "        img_name = img[11].split(\"/\")[1]\n",
    "        # Check if the image name is in the full_mammo_dict\n",
    "        if img_name in full_mammo_dict:\n",
    "            # Update the image path with the corresponding path from the full_mammo_dict\n",
    "            data.iloc[index, 11] = full_mammo_dict[img_name]\n",
    "        else:\n",
    "            print(f\"Key not found in full mammo dictionary: {img_name}\")\n",
    "            # Extract image name from the path\n",
    "        \n",
    "        img_name = img[12].split(\"/\")[2]\n",
    "        # Check if the image name is in the cropped_images_dict\n",
    "        if img_name in cropped_images_dict:\n",
    "            # Update the image path with the corresponding path from the cropped_images_dict\n",
    "            data.iloc[index, 12] = cropped_images_dict[img_name]\n",
    "        else:\n",
    "            print(f\"Key not found in cropped images dictionary: {img_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd25d577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bu işlevin temel amacı, görüntüdeki kontrastı artırmak ve görsel kaliteyi iyileştirmektir, özellikle çok parlak veya çok karanlık alanlarda detayları artırmak için kullanılır.\n",
    "def apply_clahe(image, clip_limit=2.0, grid_size=(8, 8)):\n",
    "    # Convert the image to LAB color space,  LAB renk uzayı, parlaklık (L), a (yeşil-kırmızı eksen) ve b (mavi-sarı eksen)\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Split the LAB image into L, A, and B channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    # Apply CLAHE on the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=grid_size)\n",
    "    clahe_l = clahe.apply(l)\n",
    "\n",
    "    # Merge the CLAHE enhanced L channel with the original A and B channels\n",
    "    clahe_lab = cv2.merge((clahe_l, a, b))\n",
    "\n",
    "    # Convert the LAB image back to BGR color space\n",
    "    clahe_bgr = cv2.cvtColor(clahe_lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    return clahe_bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bu Python fonksiyonu, bir hazy (sisli) görüntüdeki sis etkisini azaltan bir hava temizleme işlemi gerçekleştirir.\n",
    "def haze_reduced_local_global(hazy_image, window_size=15, epsilon=0.001):\n",
    "    # Convert the hazy image to LAB color space\n",
    "    hazy_lab = cv2.cvtColor(hazy_image, cv2.COLOR_BGR2LAB)\n",
    "    hazy_l, hazy_a, hazy_b = cv2.split(hazy_lab)\n",
    "\n",
    "    # Estimate the atmospheric light\n",
    "    atmospheric_light = np.max(hazy_l)\n",
    "\n",
    "    # Calculate the dark channel of the hazy image\n",
    "    hazy_dark = cv2.erode(hazy_l, cv2.getStructuringElement(cv2.MORPH_RECT, (window_size, window_size)))\n",
    "\n",
    "    # Estimate the transmission map\n",
    "    transmission_map = 1 - hazy_dark / atmospheric_light\n",
    "\n",
    "    # Calculate the refined transmission map\n",
    "    refined_transmission_map = cv2.max(transmission_map, epsilon)\n",
    "\n",
    "    # Calculate the inverse transmission map\n",
    "    inverse_transmission_map = 1 / refined_transmission_map\n",
    "\n",
    "    # Dehaze the image\n",
    "    dehazed_l = (hazy_l.astype(np.float32) - atmospheric_light) * inverse_transmission_map + atmospheric_light\n",
    "\n",
    "    # Clip the dehazed L channel to the valid range [0, 255]\n",
    "    dehazed_l = np.clip(dehazed_l, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Merge the dehazed L channel with the original A and B channels\n",
    "    dehazed_lab = cv2.merge((dehazed_l, hazy_a, hazy_b))\n",
    "\n",
    "    # Convert the LAB image back to BGR color space\n",
    "    dehazed_bgr = cv2.cvtColor(dehazed_lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    return dehazed_bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ad8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bu Python fonksiyonu, Convolutional Analysis Operator Learning (CAOL) çerçevesini kullanarak bir gri tonlu görüntünün özellikle düşük seviyeli öznitelikleri çıkarmak için bir sparse coding işlemi gerçekleştirir. \n",
    "def csid_caol(image_path, n_components, patch_size, iterations):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Extract patches from the image\n",
    "    patches = cv2.extract_patches_2d(image, (patch_size, patch_size))\n",
    "\n",
    "    # Reshape the patches for sparse coding\n",
    "    patches = patches.reshape(patches.shape[0], -1)\n",
    "\n",
    "    # Perform sparse coding using the Convolutional Analysis Operator Learning (CAOL) framework\n",
    "    coder = SparseCoder(dictionary=np.random.randn(patch_size * patch_size, n_components), transform_algorithm='lasso_lars')\n",
    "    codes = coder.transform(patches.T)\n",
    "\n",
    "    # Reconstruct the image using the learned codes\n",
    "    reconstructed_patches = np.dot(codes.T, coder.components_).reshape(-1, patch_size, patch_size)\n",
    "    reconstructed_image = cv2.reconstruct_patches_2d(reconstructed_patches, (image.shape[0], image.shape[1]))\n",
    "\n",
    "    return reconstructed_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8916cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_full = mpimg.imread(Data_cleaning_2.iloc[0]['image_file_path'])\n",
    "img_full_cv2 = cv2.imread(Data_cleaning_2.iloc[0]['image_file_path'], cv2.IMREAD_COLOR)\n",
    "img_full_clahe = apply_clahe(img_full_cv2)\n",
    "img_full_helg = haze_reduced_local_global(img_full_cv2)\n",
    "\n",
    "img_crop = mpimg.imread(Data_cleaning_2.iloc[0]['cropped_image_file_path'])\n",
    "#img_roi = mpimg.imread(mass_data.iloc[0]['ROI_mask_file_path'])\n",
    "    \n",
    "\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "axs[0,0].imshow(img_full, cmap='gray')\n",
    "axs[0,1].imshow(img_full_clahe, cmap='gray')\n",
    "axs[0,2].imshow(img_full_helg, cmap='gray')\n",
    "#axs[1,0].imshow(img_roi, cmap='gray')\n",
    "axs[1,2].imshow(img_crop, cmap='gray')\n",
    "\n",
    "axs[0,0].axis('off')\n",
    "axs[0,1].axis('off')\n",
    "axs[0,2].axis('off')\n",
    "axs[1,0].axis('off')\n",
    "axs[1,1].axis('off')\n",
    "\n",
    "axs[0,0].set_title('Image file path')\n",
    "axs[0,1].set_title('CLAHE')\n",
    "axs[0,2].set_title('HELG')\n",
    "axs[1,0].set_title('ROI mask file path')\n",
    "axs[1,2].set_title('Cropped image file path')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91894946",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(100)\n",
    "\n",
    "# Define a classification dictionary for pathology\n",
    "classification = {\"MALIGNANT\": 0, \"BENIGN_WITHOUT_CALLBACK\": 1, \"BENIGN\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e221a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img):\n",
    "    # Load and resize the image\n",
    "    c_img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    c_img_size = cv2.resize(c_img, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    return c_img_size\n",
    "\n",
    "def get_pathology(pathology):\n",
    "    # Sınıflandırma sözlüğünü kullanarak patolojiyi sayısal değerlerle eşleme\n",
    "    return classification[pathology]\n",
    "\n",
    "def get_images_result(dataset):\n",
    "    # Paralel görüntü yükleme için ThreadPoolExecutor'u kullanın\n",
    "    with ThreadPoolExecutor() as executor: \n",
    "        # Load images and get pathology results using parallel processing\n",
    "        images = np.array(list(executor.map(load_image, dataset.loc[:]['image_file_path'])))\n",
    "        result = np.array(list(executor.map(get_pathology, dataset.loc[:]['pathology'])))\n",
    "    # Convert pathology results to categorical format\n",
    "    result = to_categorical(result)\n",
    "    return (images, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bccaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim ve test veri kümelerini karıştırın\n",
    "mass_train_data_shuffled = Data_cleaning_2.sample(frac = 1)\n",
    "mass_test_data_shuffled = Data_cleaning_2_test.sample(frac = 1)\n",
    "# MResimleri yüklemek ve yeniden boyutlandırmak için geçen süreyi ölçün\n",
    "tic = time.perf_counter()\n",
    "(X_train, y_train) = get_images_result(mass_train_data_shuffled)\n",
    "(X_test, y_test) = get_images_result(mass_test_data_shuffled)\n",
    "toc = time.perf_counter()\n",
    "print(f\"Uploading the images and resizing in {toc - tic:0.4f} seconds\")\n",
    "# Eğitim ve test veri kümelerinin şekillerini görüntüle\n",
    "print('X_train shape : {}' .format(X_train.shape))\n",
    "print('y_train shape : {}' .format(y_train.shape))\n",
    "print('X_test shape : {}' .format(X_test.shape))\n",
    "print('y_test shape : {}' .format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e367b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def create_cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))  # Increase the number of neurons in the dense layer\n",
    "    model.add(Dropout(0.2))  # Adjust dropout rate\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))  \n",
    "    \n",
    "    # Compile the model with a lower learning rate\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    return model, early_stopping\n",
    "\n",
    "cnn_model, early_stopping = create_cnn_model(input_shape=(224, 224, 3))\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "history = cnn_model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=30, validation_data=(X_test, y_test), callbacks=early_stopping)\n",
    "\n",
    "\n",
    "# Print the final accuracy and loss\n",
    "final_loss, final_accuracy = cnn_model.evaluate(X_test, y_test)\n",
    "print(f'Final Validation Loss: {final_loss:.4f}')\n",
    "print(f'Final Validation Accuracy: {final_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "cnn_model.save(\"cnn_model.h5\")\n",
    "print(\"Model saved to disk.\")\n",
    "\n",
    "# Load the model back (optional)\n",
    "loaded_model = load_model(\"cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "def create_densenet_model(input_shape):\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    return model, early_stopping\n",
    "\n",
    "# Reshape the input data\n",
    "input_shape_densenet = (224, 224, 3)\n",
    "\n",
    "# Create and compile the modified DenseNet121 model\n",
    "densenet_model, early_stopping_densenet = create_densenet_model(input_shape_densenet)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history_densenet = densenet_model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=30, validation_data=(X_test, y_test), callbacks=[early_stopping_densenet])\n",
    "\n",
    "# Evaluate the model\n",
    "final_loss_densenet, final_accuracy_densenet = densenet_model.evaluate(X_test, y_test)\n",
    "print(f'Final Validation Loss (DenseNet): {final_loss_densenet:.4f}')\n",
    "print(f'Final Validation Accuracy (DenseNet): {final_accuracy_densenet:.4f}')\n",
    "\n",
    "# Save the DenseNet model to an h5 file\n",
    "densenet_model.save('denseNet_model_cbis.h5')\n",
    "print(\"DenseNet121 Model saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d5d83a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
